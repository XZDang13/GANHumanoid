{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6632a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from RLAlg.buffer.replay_buffer import ReplayBuffer\n",
    "from RLAlg.alg.gan import GAN\n",
    "from model import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f721e07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ReplayBuffer] Loaded buffer from 'expert_motion_buffer.pth' to device 'cpu'\n"
     ]
    }
   ],
   "source": [
    "expert_motion_buffer = ReplayBuffer(\n",
    "            4000,\n",
    "            50\n",
    "        )\n",
    "\n",
    "expert_motion_buffer.load(\"expert_motion_buffer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea455cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ReplayBuffer] Loaded buffer from 'agent_motion_buffer.pth' to device 'cpu'\n"
     ]
    }
   ],
   "source": [
    "agent_motion_buffer = ReplayBuffer(\n",
    "            4096,\n",
    "            100\n",
    "        )\n",
    "\n",
    "agent_motion_buffer.load(\"agent_motion_buffer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0673a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "discriminator = Discriminator(162).to(device)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=5e-5, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a427b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D Loss: 0.6218315362930298\n",
      "D Loss: 0.37726879119873047\n",
      "D Loss: 0.30637335777282715\n",
      "D Loss: 0.25039976835250854\n",
      "D Loss: 0.24920417368412018\n",
      "D Loss: 0.20451880991458893\n",
      "D Loss: 0.20734509825706482\n",
      "D Loss: 0.17789261043071747\n",
      "D Loss: 0.1865866631269455\n",
      "D Loss: 0.1929100751876831\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    for _ in range(100):\n",
    "        expert_batch = expert_motion_buffer.sample_tensor(\"motion_observations\", 512).to(device)\n",
    "        agent_batch = agent_motion_buffer.sample_tensor(\"motion_observations\", 512).to(device)\n",
    "        d_loss = GAN.compute_bce_loss(discriminator, expert_batch, agent_batch, r1_gamma=10.0)\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "    print(f\"D Loss: {d_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "773d436c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3458, 3.2041, 3.2586, 3.4311, 3.3480, 3.0870, 2.9051, 3.2744, 3.4602,\n",
       "        3.2038, 2.9910, 3.0244, 2.7139, 3.0946, 3.2552, 3.3256, 2.4170, 3.1778,\n",
       "        2.4522, 3.2474, 2.9685, 3.0264, 3.3553, 2.9239, 2.8648, 3.2907, 2.5992,\n",
       "        3.2912, 2.7473, 2.7147, 3.2496, 3.2725, 2.9023, 3.2700, 3.3540, 2.8471,\n",
       "        3.3533, 3.3875, 3.1990, 3.0708, 3.1803, 2.7478, 2.7571, 3.2145, 3.0765,\n",
       "        3.5315, 3.2304, 3.3504, 3.1620, 3.1696, 2.9260, 2.6476, 3.0744, 3.2035,\n",
       "        3.2984, 3.2674, 3.4514, 3.1752, 3.1358, 3.5312, 3.0930, 3.3094, 3.4476,\n",
       "        3.3822, 3.2906, 3.3051, 3.3247, 3.2567, 3.0303, 2.5080, 1.2556, 3.1886,\n",
       "        3.2615, 2.8301, 3.0085, 3.0241, 3.3184, 3.3778, 2.7850, 3.1001, 3.3020,\n",
       "        3.5498, 3.3863, 3.1668, 2.7846, 3.0536, 3.4325, 2.9898, 3.4032, 3.2030,\n",
       "        3.2536, 2.8868, 2.4072, 3.2087, 3.5455, 3.2593, 3.2646, 2.9787, 3.2888,\n",
       "        3.1218, 3.2812, 3.2989, 3.1794, 2.8076, 3.5271, 3.2395, 3.2735, 3.5454,\n",
       "        2.6076, 3.3423, 3.3833, 3.3731, 2.5100, 3.1403, 3.3560, 3.1918, 3.0640,\n",
       "        3.0694, 3.2872, 3.2197, 3.3350, 3.2808, 3.0601, 3.2386, 3.4575, 3.2255,\n",
       "        3.3134, 3.2591, 3.3895, 1.2556, 3.1830, 2.6684, 3.2170, 3.1169, 3.2454,\n",
       "        3.3912, 3.2784, 3.2814, 3.3486, 3.4746, 2.5494, 2.6016, 3.4468, 3.0060,\n",
       "        3.5245, 2.7098, 3.1576, 3.3411, 3.3444, 3.4189, 3.2467, 3.3142, 3.0513,\n",
       "        3.2264, 3.3315, 3.6061, 3.0350, 2.9985, 3.2472, 3.3357, 3.3273, 3.4024,\n",
       "        3.2761, 2.6766, 3.1342, 3.1565, 3.3329, 3.0315, 3.0959, 3.2809, 2.6380,\n",
       "        3.3195, 3.2782, 3.0122, 3.1422, 3.2753, 3.2542, 3.5591, 3.2690, 3.0460,\n",
       "        3.2987, 3.2443, 2.8848, 2.9050, 3.1009, 2.9480, 3.2942, 3.3186, 2.9617,\n",
       "        3.3424, 3.3833, 3.2199, 3.1932, 3.3360, 3.5261, 2.5693, 2.5831, 3.2542,\n",
       "        2.8781, 3.3181, 3.3285, 3.5147, 3.1819, 3.4364, 3.0419, 3.0682, 3.4523,\n",
       "        2.9007, 3.2687, 2.6099, 2.9504, 2.7352, 2.9409, 3.2861, 3.0711, 3.1860,\n",
       "        3.0063, 3.2219, 3.3671, 3.6425, 3.0856, 3.1021, 2.7995, 3.3652, 3.3214,\n",
       "        3.2240, 3.2484, 3.5428, 3.1277, 3.1673, 3.3404, 3.4799, 2.8547, 3.2586,\n",
       "        2.7491, 3.2677, 3.0699, 2.9629, 3.2002, 3.2279, 3.1506, 3.2381, 3.0455,\n",
       "        2.2466, 3.2923, 2.7493, 3.1899, 3.3371, 3.6340, 2.7214, 3.0040, 3.5414,\n",
       "        3.2733, 3.3450, 3.1307, 2.8937, 3.2625, 3.1869, 3.2415, 3.0443, 3.0298,\n",
       "        2.9042, 2.8619, 3.1849, 3.2917, 3.3772, 3.2596, 3.3298, 3.2802, 3.3218,\n",
       "        3.3840, 3.2717, 3.2126, 3.0427, 2.9755, 2.9651, 2.9336, 3.2867, 3.0858,\n",
       "        2.9577, 3.3838, 3.2002, 3.3437, 3.4711, 3.1168, 3.2683, 2.6952, 2.8449,\n",
       "        3.1153, 3.0958, 3.4327, 3.2218, 3.0028, 3.2180, 3.2965, 3.3298, 3.1489,\n",
       "        2.8878, 3.3502, 3.1069, 3.1192, 3.3194, 3.3110, 3.0564, 3.2827, 3.2903,\n",
       "        3.2339, 3.1724, 3.1331, 3.4317, 2.8649, 3.3306, 2.9735, 2.9248, 3.2682,\n",
       "        3.2577, 3.1334, 3.0185, 2.7287, 3.5702, 3.2686, 3.2820, 3.1948, 3.2309,\n",
       "        3.1041, 3.4631, 3.0164, 3.0933, 3.1923, 2.7858, 3.0483, 2.9438, 3.2636,\n",
       "        3.2139, 3.3503, 2.6877, 3.0155, 3.3534, 3.3652, 2.7963, 3.1864, 3.6096,\n",
       "        2.6434, 3.2518, 3.3459, 3.4515, 2.9244, 2.8295, 2.9719, 3.3593, 3.3943,\n",
       "        3.4018, 3.1555, 3.0763, 3.0784, 3.2825, 3.4623, 3.3498, 3.2183, 3.2753,\n",
       "        3.2428, 3.2160, 3.1267, 3.3378, 3.1565, 3.1284, 3.1321, 3.1897, 3.2587,\n",
       "        2.6013, 3.2502, 2.7182, 2.4750, 3.3428, 3.1949, 2.6606, 3.2519, 3.2060,\n",
       "        3.3790, 2.9886, 2.9559, 3.2852, 3.4200, 3.1144, 3.4406, 3.3678, 2.8218,\n",
       "        3.2512, 3.1645, 2.5970, 3.2047, 3.0058, 3.2649, 3.1751, 3.2603, 2.9128,\n",
       "        2.7668, 3.3584, 3.3189, 3.0767, 3.3284, 3.2830, 3.5426, 3.3172, 2.8177,\n",
       "        3.5254, 2.4102, 3.1965, 3.1979, 2.4161, 3.2849, 3.2105, 3.2190, 3.4476,\n",
       "        2.8200, 3.5459, 3.3024, 3.0783, 3.2412, 3.1215, 3.0531, 3.5623, 3.6465,\n",
       "        2.7696, 3.3662, 3.4319, 3.3284, 3.4178, 3.4526, 2.7461, 2.4622, 3.1154,\n",
       "        3.3465, 3.3021, 3.4356, 3.2498, 3.2954, 3.0332, 3.3021, 3.3029, 3.1311,\n",
       "        3.3014, 3.3874, 3.2707, 2.9632, 3.4474, 2.7942, 3.3061, 3.0681, 3.2609,\n",
       "        2.8127, 3.4858, 3.3228, 3.2048, 2.8816, 3.1814, 2.9303, 3.0709, 3.0019,\n",
       "        2.7585, 3.4301, 3.3427, 2.9445, 3.2687, 3.4976, 3.3262, 3.5447, 3.0891,\n",
       "        3.1815, 3.1077, 3.3227, 2.6777, 3.2228, 3.2367, 3.4454, 3.2090, 2.6989,\n",
       "        2.5300, 1.2556, 3.0774, 3.4212, 3.2878, 3.3447, 3.4668, 2.8363, 2.6659,\n",
       "        3.6387, 2.4110, 3.5307, 3.2264, 2.8741, 2.9047, 3.1197, 3.3028, 3.0449,\n",
       "        2.8532, 3.2001, 3.2945, 3.2319, 3.4901, 3.2804, 3.4646, 2.8741, 3.3261,\n",
       "        3.3835, 3.0930, 3.2743, 3.3071, 3.0573, 3.3397, 3.5272, 3.2856],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator(expert_batch).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d10f3820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.0699, -5.8882, -6.5883, -6.2400, -6.1303, -6.4090, -6.4638, -6.4100,\n",
       "        -5.3395, -6.6100, -6.8150, -6.7138, -4.6272, -6.8212, -6.3236, -6.4284,\n",
       "        -6.3121, -7.0367, -6.1543, -5.8994, -6.1916, -6.2250, -5.2479, -5.8638,\n",
       "        -6.4845, -5.7563,  2.0855,  2.5283, -5.4110, -5.8330, -6.7026, -6.0699,\n",
       "        -6.5025, -6.6413, -5.2223, -6.4798, -6.4142, -5.3408, -6.4076, -6.1247,\n",
       "         2.1195, -6.7174, -7.0353, -6.3076, -6.0100, -6.8725, -6.6936, -5.9182,\n",
       "        -6.3658, -6.1500, -6.3888, -5.7856, -5.5573, -6.0058, -5.9831, -7.0124,\n",
       "        -6.3184, -6.4986, -6.0438, -6.1974, -5.4265, -6.8575,  1.8093, -6.4482,\n",
       "        -6.6157, -6.3222, -6.4163, -6.6540, -5.7059, -6.7192, -6.7004, -6.4311,\n",
       "        -6.3334, -6.4189, -6.6007, -6.6673, -6.7685, -6.1694, -6.2645, -6.7084,\n",
       "        -6.3977, -6.0023, -6.7638, -6.8113, -6.3739, -6.0576, -6.9409, -6.0534,\n",
       "        -5.9949, -4.2281, -6.2391, -6.3282, -6.1411, -5.5535, -6.3428, -0.0543,\n",
       "         2.0727, -6.7326, -6.4241, -6.3318, -5.5444, -5.9427, -6.5654, -6.8789,\n",
       "        -7.0906, -4.9613, -5.6299, -6.3659, -6.2167, -6.2872, -6.4687, -6.6937,\n",
       "        -6.2836, -6.1151, -6.0467, -6.4888, -6.7915, -6.5966, -6.8516, -6.6495,\n",
       "        -2.5146, -6.6203, -5.9367, -6.4737, -2.9780, -5.0207, -6.4496, -6.3815,\n",
       "        -6.5387, -4.5957, -6.3904, -5.7721, -5.7630, -6.3081, -6.4391, -3.9834,\n",
       "        -6.2501, -6.6025, -6.0101, -5.6865, -6.6011, -6.3571, -6.0141,  2.2046,\n",
       "        -6.0695, -5.3278, -5.3471, -5.8684,  1.7444, -6.3494, -6.2535, -5.1435,\n",
       "        -6.2633, -6.7235, -6.4853, -5.7911, -1.1337, -6.8955, -7.0353, -2.9338,\n",
       "        -6.6272, -6.1990, -6.0223, -6.6735, -6.9933, -6.0311, -6.7292, -6.3290,\n",
       "        -5.1442,  1.7665, -6.0018, -6.2827, -3.5283, -5.9853, -5.8506, -6.2792,\n",
       "        -6.5991, -5.9995, -5.8505, -6.1711, -4.4903, -6.3326, -6.6514, -6.4639,\n",
       "         1.6428, -6.6829, -6.2117, -6.2414, -5.6473, -6.1961, -6.6033, -6.6580,\n",
       "        -6.3686,  2.7320, -5.0750, -6.6455, -6.5205, -6.3396,  2.5191, -6.1546,\n",
       "        -6.5789, -6.6911, -6.0925, -6.8280,  2.2943, -0.3083, -5.6198, -6.0453,\n",
       "        -6.7141, -4.1832, -3.2837, -6.4552,  1.7992, -5.5220, -3.3596, -6.7596,\n",
       "        -6.1676, -6.3790, -6.3439, -6.1802, -6.4448, -6.5020, -5.6883, -5.7640,\n",
       "         2.4525, -6.4217, -6.5877, -5.4314, -6.3735, -6.6387, -6.7193, -5.9652,\n",
       "        -4.7217, -6.3496, -6.6586, -6.6560, -6.5026, -6.2926, -6.4669, -5.9966,\n",
       "        -6.4096, -6.2107, -6.3753, -6.1744, -6.4241, -6.3684, -5.9939, -6.4744,\n",
       "        -6.2749, -6.7142, -5.3703, -6.7144, -6.3980, -6.4179, -6.6891, -6.6810,\n",
       "        -6.2476, -6.6043, -6.3323, -6.4105, -6.2972,  2.1418, -6.8701, -6.7859,\n",
       "        -6.1664, -5.2868,  0.8670, -6.1816, -5.9827, -6.2852, -6.6461, -0.0172,\n",
       "        -6.2456, -6.0230, -6.6287, -6.3951, -6.3993, -6.6038,  1.2355, -6.3240,\n",
       "        -6.6190, -6.1969, -6.1119, -6.0852, -5.1403, -6.2439,  1.0039, -6.8181,\n",
       "        -5.4595, -3.0318, -6.7021, -6.3252, -6.2926, -6.2508, -6.6536, -6.7505,\n",
       "        -6.5378, -6.8776, -5.4853, -6.2463, -6.3386,  1.9124, -5.8853, -3.6258,\n",
       "        -6.2900, -6.1684, -6.3767, -6.4827, -5.4551, -5.7778, -6.0111, -5.9995,\n",
       "        -5.8945, -5.3724, -5.2931, -6.0744, -6.2653, -6.1335, -4.7231, -6.4069,\n",
       "        -5.8396, -6.3034, -7.1520, -6.5733, -6.1428, -6.1645, -6.5494, -6.5239,\n",
       "        -6.6870, -3.3365,  0.7022, -6.5761, -5.9749, -6.1601, -6.5286, -6.6489,\n",
       "        -6.1367, -6.4047, -6.5356, -6.4559, -6.3689, -5.8356, -6.6243, -6.4772,\n",
       "        -6.5950, -6.8169, -6.0423, -6.3445, -5.9725, -6.4443, -6.5063, -6.8806,\n",
       "        -5.9989, -6.2865, -6.6241, -6.3407, -3.6928, -6.1275, -6.0203, -6.4362,\n",
       "        -6.3485, -6.7467, -6.8682, -6.4816, -6.6210, -6.7848, -6.4578, -6.8595,\n",
       "        -6.3689, -4.7456, -6.1508, -6.3305, -6.7051, -6.5835, -6.0612, -6.4184,\n",
       "        -6.6044, -5.9799, -6.6000, -6.3566, -6.4103, -6.5812, -3.5471, -6.4771,\n",
       "        -6.1289, -5.6017, -3.4716, -5.8981,  1.2163, -5.7878, -5.7496, -6.1605,\n",
       "        -6.3173,  1.8080, -6.4744, -6.1728, -6.8831, -6.3524, -6.3488, -6.5503,\n",
       "        -5.7042, -3.2490, -6.9785, -6.5673, -6.4646, -5.6725, -6.2730, -6.6702,\n",
       "        -6.1415, -5.8707, -6.4686, -5.6979, -6.2694,  2.6508, -6.5385, -6.1773,\n",
       "        -7.0884, -6.5655, -6.0478, -6.0793, -6.5150, -6.5309, -6.3153, -6.3708,\n",
       "        -6.4733, -6.2439, -7.0969, -6.1566, -5.8547, -6.2988, -6.2252, -6.4350,\n",
       "        -6.9987, -6.5152, -6.3840, -6.8558, -2.8766, -5.8538, -6.1564, -5.8898,\n",
       "        -5.7382, -6.3445, -5.0535, -6.1948, -6.4371, -6.0926, -6.1227, -6.6511,\n",
       "        -5.8182, -6.8488, -6.1373, -5.7989, -5.9934, -6.2999, -6.8651, -5.6106,\n",
       "        -5.0573, -6.4121, -6.6744, -6.3033, -6.6970, -6.4755, -6.0573, -6.4658,\n",
       "        -6.4456, -6.1144, -5.4988, -6.3682, -6.1053, -6.3094,  0.1375, -6.9853,\n",
       "        -6.6261, -4.9648, -6.3199, -4.4935, -4.2637, -5.1685, -6.9581, -6.8986,\n",
       "        -6.1799, -5.2515, -6.9546, -6.9125, -6.4385, -5.2935, -6.0714, -6.5678,\n",
       "        -6.1063, -5.0475, -5.9551, -5.2493, -6.1459, -6.1253, -5.9273, -5.9646,\n",
       "        -6.2686, -5.5703, -6.3102, -6.7671, -6.0119, -6.2632, -6.5652, -5.7844,\n",
       "        -5.0269, -6.7670, -6.3845, -5.5201, -6.2281, -6.6492, -6.8308, -5.0201],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator(agent_batch).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e565a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3802, 3.2437, 3.2961, 3.4626, 3.3822, 3.1314, 2.9582, 3.3112, 3.4909,\n",
       "        3.2433, 3.0398, 3.0717, 2.7780, 3.1387, 3.2927, 3.3606, 2.5023, 3.2184,\n",
       "        2.5347, 3.2853, 3.0184, 3.0735, 3.3893, 2.9760, 2.9201, 3.3269, 2.6707,\n",
       "        3.3275, 2.8093, 2.7787, 3.2873, 3.3094, 2.9555, 3.3071, 3.3881, 2.9033,\n",
       "        3.3874, 3.4204, 3.2387, 3.1159, 3.2208, 2.8098, 2.8184, 3.2536, 3.1214,\n",
       "        3.5600, 3.2689, 3.3846, 3.2032, 3.2106, 2.9781, 2.7158, 3.1193, 3.2430,\n",
       "        3.3344, 3.3045, 3.4823, 3.2159, 3.1781, 3.5597, 3.1371, 3.3450, 3.4786,\n",
       "        3.4153, 3.3269, 3.3408, 3.3598, 3.2942, 3.0772, 2.5862, 1.5062, 3.2287,\n",
       "        3.2989, 2.8873, 3.0565, 3.0714, 3.3537, 3.4110, 2.8447, 3.1439, 3.3379,\n",
       "        3.5778, 3.4192, 3.2078, 2.8444, 3.0994, 3.4640, 3.0387, 3.4356, 3.2425,\n",
       "        3.2913, 2.9409, 2.4933, 3.2481, 3.5736, 3.2967, 3.3018, 3.0281, 3.3251,\n",
       "        3.1647, 3.3178, 3.3349, 3.2199, 2.8660, 3.5557, 3.2777, 3.3104, 3.5735,\n",
       "        2.6786, 3.3767, 3.4164, 3.4065, 2.5880, 3.1824, 3.3900, 3.2318, 3.1094,\n",
       "        3.1146, 3.3236, 3.2586, 3.3697, 3.3174, 3.1057, 3.2768, 3.4882, 3.2642,\n",
       "        3.3489, 3.2966, 3.4223, 1.5062, 3.2234, 2.7353, 3.2560, 3.1600, 3.2834,\n",
       "        3.4240, 3.3151, 3.3180, 3.3828, 3.5048, 2.6245, 2.6730, 3.4778, 3.0541,\n",
       "        3.5532, 2.7740, 3.1990, 3.3756, 3.3788, 3.4508, 3.2846, 3.3496, 3.0973,\n",
       "        3.2650, 3.3663, 3.6325, 3.0818, 3.0469, 3.2851, 3.3703, 3.3623, 3.4349,\n",
       "        3.3129, 2.7430, 3.1766, 3.1979, 3.3677, 3.0784, 3.1399, 3.3176, 2.7069,\n",
       "        3.3548, 3.3149, 3.0600, 3.1842, 3.3121, 3.2919, 3.5868, 3.3061, 3.0922,\n",
       "        3.3347, 3.2823, 2.9390, 2.9581, 3.1447, 2.9989, 3.3303, 3.3538, 3.0119,\n",
       "        3.3768, 3.4164, 3.2589, 3.2332, 3.3707, 3.5547, 2.6430, 2.6558, 3.2918,\n",
       "        2.9326, 3.3534, 3.3634, 3.5436, 3.2223, 3.4677, 3.0883, 3.1134, 3.4831,\n",
       "        2.9540, 3.3057, 2.6807, 3.0012, 2.7979, 2.9921, 3.3226, 3.1162, 3.2263,\n",
       "        3.0543, 3.2608, 3.4007, 3.6680, 3.1301, 3.1458, 2.8584, 3.3989, 3.3566,\n",
       "        3.2628, 3.2863, 3.5710, 3.1703, 3.2083, 3.3749, 3.5099, 2.9105, 3.2961,\n",
       "        2.8110, 3.3048, 3.1150, 3.0130, 3.2398, 3.2665, 3.1923, 3.2763, 3.0918,\n",
       "        2.3471, 3.3285, 2.8111, 3.2300, 3.3718, 3.6597, 2.7849, 3.0521, 3.5696,\n",
       "        3.3102, 3.3794, 3.1733, 2.9474, 3.2998, 3.2271, 3.2796, 3.0906, 3.0768,\n",
       "        2.9573, 2.9173, 3.2252, 3.3279, 3.4104, 3.2970, 3.3647, 3.3169, 3.3569,\n",
       "        3.4171, 3.3087, 3.2518, 3.0891, 3.0250, 3.0152, 2.9852, 3.3231, 3.1302,\n",
       "        3.0082, 3.4168, 3.2399, 3.3781, 3.5014, 3.1599, 3.3053, 2.7604, 2.9012,\n",
       "        3.1585, 3.1398, 3.4642, 3.2606, 3.0510, 3.2570, 3.3326, 3.3647, 3.1907,\n",
       "        2.9418, 3.3844, 3.1505, 3.1622, 3.3546, 3.3465, 3.1021, 3.3193, 3.3266,\n",
       "        3.2723, 3.2132, 3.1755, 3.4632, 2.9202, 3.3655, 3.0231, 2.9769, 3.3053,\n",
       "        3.2952, 3.1758, 3.0660, 2.7918, 3.5976, 3.3056, 3.3186, 3.2347, 3.2694,\n",
       "        3.1478, 3.4936, 3.0640, 3.1374, 3.2323, 2.8455, 3.0945, 2.9949, 3.3008,\n",
       "        3.2530, 3.3845, 2.7534, 3.0631, 3.3875, 3.3988, 2.8554, 3.2267, 3.6359,\n",
       "        2.7120, 3.2895, 3.3803, 3.4824, 2.9765, 2.8867, 3.0216, 3.3932, 3.4270,\n",
       "        3.4343, 3.1969, 3.1212, 3.1232, 3.3191, 3.4929, 3.3840, 3.2573, 3.3121,\n",
       "        3.2808, 3.2551, 3.1694, 3.3724, 3.1979, 3.1710, 3.1745, 3.2298, 3.2961,\n",
       "        2.6727, 3.2880, 2.7820, 2.5557, 3.3772, 3.2348, 2.7280, 3.2896, 3.2455,\n",
       "        3.4122, 3.0376, 3.0064, 3.3216, 3.4519, 3.1576, 3.4718, 3.4014, 2.8794,\n",
       "        3.2889, 3.2056, 2.6687, 3.2442, 3.0539, 3.3021, 3.2158, 3.2977, 2.9655,\n",
       "        2.8276, 3.3923, 3.3541, 3.1216, 3.3633, 3.3196, 3.5708, 3.3526, 2.8755,\n",
       "        3.5540, 2.4961, 3.2363, 3.2377, 2.5015, 3.3214, 3.2498, 3.2580, 3.4786,\n",
       "        2.8777, 3.5740, 3.3382, 3.1231, 3.2793, 3.1644, 3.0990, 3.5899, 3.6719,\n",
       "        2.8302, 3.3998, 3.4634, 3.3634, 3.4498, 3.4834, 2.8082, 2.5439, 3.1586,\n",
       "        3.3808, 3.3379, 3.4669, 3.2876, 3.3315, 3.0800, 3.3379, 3.3387, 3.1736,\n",
       "        3.3373, 3.4203, 3.3077, 3.0134, 3.4784, 2.8534, 3.3418, 3.1133, 3.2982,\n",
       "        2.8709, 3.5157, 3.3579, 3.2443, 2.9359, 3.2218, 2.9821, 3.1160, 3.0501,\n",
       "        2.8197, 3.4616, 3.3772, 2.9956, 3.3058, 3.5271, 3.3613, 3.5729, 3.1334,\n",
       "        3.2219, 3.1512, 3.3578, 2.7440, 3.2617, 3.2749, 3.4765, 3.2484, 2.7638,\n",
       "        2.6065, 1.5062, 3.1223, 3.4531, 3.3242, 3.3790, 3.4972, 2.8931, 2.7330,\n",
       "        3.6642, 2.4968, 3.5592, 3.2651, 2.9288, 2.9579, 3.1627, 3.3387, 3.0911,\n",
       "        2.9091, 3.2398, 3.3306, 3.2704, 3.5198, 3.3170, 3.4951, 2.9289, 3.3611,\n",
       "        3.4165, 3.1371, 3.3112, 3.3428, 3.1030, 3.3743, 3.5559, 3.3221],\n",
       "       device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(1 - 1 / (1 + torch.exp(-discriminator(expert_batch).value)) + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee10e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaaclab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
